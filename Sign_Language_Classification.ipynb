{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79dede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader \n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7967e4",
   "metadata": {},
   "source": [
    "# Create Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b753e2a3-8b34-422c-a330-36bf41c5689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignLanguageDigits(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, shape, train=True, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize(shape),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Split data into train/test (80/20)\n",
    "        for label in range(10):\n",
    "            digit_dir = os.path.join(root_dir, str(label))\n",
    "            images = [img for img in os.listdir(digit_dir) if img.endswith('.JPG')]\n",
    "            split_idx = int(0.8 * len(images))   \n",
    "            \n",
    "            if train:\n",
    "                images = images[:split_idx]\n",
    "            else:\n",
    "                images = images[split_idx:]\n",
    "                \n",
    "            for img_name in images:\n",
    "                self.image_paths.append(os.path.join(digit_dir, img_name))\n",
    "                self.labels.append(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')  # Ensure 3 channels\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e9f331",
   "metadata": {},
   "source": [
    "# Create and Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27689074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "\n",
    "# Replace the MNIST dataset loading with:\n",
    "train_dataset = SignLanguageDigits(\n",
    "    root_dir='Sign-Language-Digits-Dataset/Dataset',\n",
    "    shape=(64, 64),  # Resize to 64x64\n",
    "    train=True\n",
    ")\n",
    "\n",
    "test_dataset = SignLanguageDigits(\n",
    "    root_dir='Sign-Language-Digits-Dataset/Dataset',\n",
    "    shape=(64, 64),\n",
    "    train=False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "class NN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, num_classes): # constructor of NN with its attributes\n",
    "\n",
    "        super(NN, self).__init__() # calling constructor of base class  \n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "        # callable objects\n",
    "\n",
    "    def forward(self, x):  # we must provid imp of forward () of nn.Module in our subclass\n",
    "\n",
    "        x = F.relu(self.fc1(x)) # //can do F.softmax(self.fc1(x))\n",
    " \n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        x = self.fc3(x)  #         x = F.softmax(self.fc3(x), dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size = 12288 # 3x64x64 = 12,288 size of sign images (RGB)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "# create NN object and move it to device\n",
    "\n",
    "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    " \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "\n",
    "        # Get data to cuda if possible\n",
    "\n",
    "        data = data.to(device=device)\n",
    "\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        data = data.reshape(data.shape[0], -1) #[64,3x64x64]=[64, 12288]\n",
    "\n",
    "        # forward propagation\n",
    "\n",
    "        scores = model(data) #automatically call the forward method,\n",
    "\n",
    "\n",
    "        loss = criterion(scores, targets) # compute cost/loss on 64 example\n",
    "\n",
    "        # zero previous gradients\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "       \n",
    "        # back-propagation\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda44d8",
   "metadata": {},
   "source": [
    "# Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca70d8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: \n",
      "torch.Size([64, 12288])\n",
      "torch.Size([64, 10])\n",
      "Got 55 / 64 with accuracy 85.94\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # 1. our model deactivates all the layers (eg.batch normalization/dropout)\n",
    "    with torch.no_grad(): #2.  not make computational graph\n",
    "        for x, y in loader:\n",
    "            #print (x.shape)\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "           \n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            print(x.shape)\n",
    "            #print (y.shape)\n",
    "            \n",
    "            scores = model(x)\n",
    "            print(scores.shape)\n",
    "                      \n",
    "            _, predictions = scores.max(1) #. it return max value and its index, 1 mean see column-wise \n",
    "            \n",
    "            num_correct += (predictions == y).sum() # compare prediction with y, if equal sum them to count the number of same values\n",
    "            num_samples += predictions.size(0)  #64, get no of samples\n",
    "            break  # just to see the results for a single patch\n",
    "        print(\n",
    "            f\"Got {num_correct} / {num_samples} with accuracy\"\n",
    "            f\" {float(num_correct) / float(num_samples) * 100:.2f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "        \n",
    "print (\"Test accuracy: \")\n",
    "check_accuracy(test_loader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
